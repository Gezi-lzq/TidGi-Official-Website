created: 20230718015127147
creator: 林一二
modified: 20230718022246480
modifier: 林一二
tags: 太记功能手册
title: 本地AI助手

本地 AI 配置教程：

# 至少 [[v0.8.1-prerelease3|https://github.com/tiddly-gittly/TidGi-Desktop/releases/tag/v0.8.1-prerelease3]] 或更高版本的太记
## 安装并打开太记，打开[[太记设置]]，找到[[语言模型设置]]，点击其中的「打开模型文件夹」按钮，打开放模型的文件夹。
## 注意文件夹名是 `language-model`
# 下载 [[huggingface/vicuna/ggml-vicuna-7b-1.1|https://huggingface.co/vicuna/ggml-vicuna-7b-1.1/tree/main]] 上的 `ggml-vic7b-q5_1.bin` AI 模型文件
## 将下载的 `ggml-vic7b-q5_1.bin` 模型文件改名为 `llama.bin` （或在[[语言模型设置]]中修改要加载的模型文件名，默认为 `llama.bin`）
## 你也可以选择下载更小但更笨的 `ggml-vic7b-q4_0.bin` 模型，或 [[ggml-vicuna-13b-1.1|https://huggingface.co/vicuna/ggml-vicuna-13b-1.1]]上更大更聪明更慢的模型
## 也有专家建议下载名字里带 `uncensored` 的模型，因为[[不对齐，反而性能更好|https://www.51cto.com/article/757320.html]]
# 将 `llama.bin` 放入刚刚你点按钮打开的模型文件夹 `language-model`
# 可以开始使用了！

使用教程：

# 确保你已安装 `linonetwo/tidgi-language-model` 太微插件
## 这样侧边栏会有一个「TG AI」标签页
## 新版太记新建的工作区会预置这个插件
# 在Wiki里打开侧边栏的「TG AI」标签页
# 问 AI 简单的问题，例如 `什么是Tiddlywiki？`
# 等待 AI 计算结果
## 由于本地化 AI 目前是使用 CPU 计算的，速度没有云端 GPU AI 快，需要耐心等待一段时间
## 如果你的电脑存储不是使用固态硬盘，还会需要一段时间加载
## 可以通过打开Windows任务管理器看看CPU是否在满速运行，来看AI是否在计算中